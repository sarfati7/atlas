---
phase: 01-foundation-data-architecture
plan: 05
type: execute
wave: 4
depends_on: ["01-03", "01-04"]
files_modified:
  - backend/src/atlas/domain/interfaces/sync_service.py
  - backend/src/atlas/adapters/sync/__init__.py
  - backend/src/atlas/adapters/sync/git_catalog_sync.py
  - backend/src/atlas/entrypoints/api/routes/webhooks.py
  - backend/src/atlas/entrypoints/dependencies.py
autonomous: true

must_haves:
  truths:
    - "Git repository changes are detected and reflected in database catalog metadata"
    - "New files in skills/, mcps/, tools/ create corresponding CatalogItem records"
    - "Deleted files in git remove corresponding CatalogItem records"
    - "Modified files update CatalogItem metadata (updated_at timestamp)"
    - "Sync can be triggered via webhook endpoint or manual call"
  artifacts:
    - path: "backend/src/atlas/domain/interfaces/sync_service.py"
      provides: "Abstract sync service interface"
      contains: "class AbstractSyncService"
    - path: "backend/src/atlas/adapters/sync/git_catalog_sync.py"
      provides: "Git-to-database sync implementation"
      contains: "class GitCatalogSyncService"
    - path: "backend/src/atlas/entrypoints/api/routes/webhooks.py"
      provides: "GitHub webhook endpoint for push events"
      contains: "async def github_webhook"
  key_links:
    - from: "backend/src/atlas/adapters/sync/git_catalog_sync.py"
      to: "backend/src/atlas/domain/interfaces/content_repository.py"
      via: "uses content repository to list git files"
      pattern: "AbstractContentRepository"
    - from: "backend/src/atlas/adapters/sync/git_catalog_sync.py"
      to: "backend/src/atlas/domain/interfaces/catalog_repository.py"
      via: "uses catalog repository to update database"
      pattern: "AbstractCatalogRepository"
    - from: "backend/src/atlas/entrypoints/api/routes/webhooks.py"
      to: "backend/src/atlas/adapters/sync/git_catalog_sync.py"
      via: "webhook triggers sync service"
      pattern: "sync_service\\.sync"
---

<objective>
Implement sync mechanism to keep database catalog metadata in sync with git content changes.

Purpose: Per Success Criteria SC-03 from ROADMAP.md, the database catalog metadata must stay synchronized with git content. When files are added, modified, or deleted in the git repository (either through direct commits or via the content repository), the catalog_items table must reflect those changes.

Output: Working sync service with webhook endpoint that detects git changes and updates database catalog accordingly.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-foundation-data-architecture/01-CONTEXT.md
@.planning/phases/01-foundation-data-architecture/01-RESEARCH.md
@.planning/phases/01-foundation-data-architecture/01-03-SUMMARY.md
@.planning/phases/01-foundation-data-architecture/01-04-SUMMARY.md
@CLAUDE.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create sync service interface and implementation</name>
  <files>
    backend/src/atlas/domain/interfaces/sync_service.py
    backend/src/atlas/domain/interfaces/__init__.py
    backend/src/atlas/adapters/sync/__init__.py
    backend/src/atlas/adapters/sync/git_catalog_sync.py
  </files>
  <action>
Create the sync service abstraction and implementation per RESEARCH.md recommendation.

1. **AbstractSyncService** (`domain/interfaces/sync_service.py`):
   ```python
   from abc import ABC, abstractmethod
   from dataclasses import dataclass
   from typing import List

   @dataclass
   class SyncResult:
       """Result of a sync operation."""
       created: int  # Number of new catalog items created
       updated: int  # Number of catalog items updated
       deleted: int  # Number of catalog items deleted
       errors: List[str]  # Any errors encountered

   class AbstractSyncService(ABC):
       @abstractmethod
       async def sync_all(self) -> SyncResult:
           """Full sync: compare all git files with database and reconcile."""
           raise NotImplementedError

       @abstractmethod
       async def sync_paths(self, paths: List[str]) -> SyncResult:
           """Partial sync: sync only specified paths (from webhook payload)."""
           raise NotImplementedError
   ```

2. **GitCatalogSyncService** (`adapters/sync/git_catalog_sync.py`):
   - Constructor takes `content_repo: AbstractContentRepository`, `catalog_repo: AbstractCatalogRepository`, and `default_author_id: UUID` (for items created without explicit author)

   Implement `sync_all()`:
   - List all files from content repo: `skills/`, `mcps/`, `tools/`
   - Get all existing catalog items from database
   - Compare:
     - Files in git but not in DB -> create CatalogItem
     - Files in DB but not in git -> delete CatalogItem
     - Files in both -> update updated_at if content changed (compare hashes if available)

   Implement `sync_paths(paths: List[str])`:
   - For each path in paths:
     - Determine type from path prefix (`skills/` -> SKILL, etc.)
     - Check if file exists in git
     - If exists in git but not DB: create
     - If exists in both: update
     - If not in git but in DB: delete

   Helper methods:
   - `_path_to_type(path: str) -> Optional[CatalogItemType]`: Map path prefix to type
   - `_extract_name(path: str) -> str`: Extract name from path (filename without extension)
   - `_create_catalog_item(path: str, type: CatalogItemType) -> CatalogItem`: Build entity from path

3. Update `domain/interfaces/__init__.py` to export `AbstractSyncService` and `SyncResult`.

4. Create `adapters/sync/__init__.py` exporting `GitCatalogSyncService`.
  </action>
  <verify>
Run `cd backend && python -c "
from atlas.domain.interfaces import AbstractSyncService, SyncResult
from atlas.adapters.sync import GitCatalogSyncService

# Check inheritance
from atlas.domain.interfaces.sync_service import AbstractSyncService as Base
print(f'GitCatalogSyncService inherits Abstract: {issubclass(GitCatalogSyncService, Base)}')

# Check SyncResult structure
result = SyncResult(created=1, updated=2, deleted=0, errors=[])
print(f'SyncResult works: created={result.created}, updated={result.updated}')
print('Sync service interface and implementation OK')
"`.
  </verify>
  <done>
AbstractSyncService interface defined in domain layer, GitCatalogSyncService implements full and partial sync logic.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create webhook endpoint for GitHub push events</name>
  <files>
    backend/src/atlas/entrypoints/api/routes/__init__.py
    backend/src/atlas/entrypoints/api/routes/webhooks.py
    backend/src/atlas/entrypoints/dependencies.py
  </files>
  <action>
Create GitHub webhook endpoint that triggers sync on push events.

1. **Webhook route** (`entrypoints/api/routes/webhooks.py`):
   ```python
   import hmac
   import hashlib
   from typing import Annotated, Optional
   from fastapi import APIRouter, Request, HTTPException, Depends, Header

   from atlas.config import settings
   from atlas.domain.interfaces import AbstractSyncService, SyncResult
   from atlas.entrypoints.dependencies import get_sync_service

   router = APIRouter(prefix="/webhooks", tags=["webhooks"])

   def verify_github_signature(payload: bytes, signature: Optional[str], secret: str) -> bool:
       """Verify GitHub webhook signature (HMAC SHA-256)."""
       if not signature or not secret:
           return False
       expected = "sha256=" + hmac.new(
           secret.encode(), payload, hashlib.sha256
       ).hexdigest()
       return hmac.compare_digest(expected, signature)

   @router.post("/github")
   async def github_webhook(
       request: Request,
       sync_service: Annotated[AbstractSyncService, Depends(get_sync_service)],
       x_hub_signature_256: Optional[str] = Header(None),
       x_github_event: Optional[str] = Header(None),
   ) -> dict:
       """
       Handle GitHub webhook events.

       Verifies signature (if GITHUB_WEBHOOK_SECRET configured),
       extracts changed files from push event, triggers partial sync.
       """
       payload = await request.body()

       # Verify signature if secret is configured
       if settings.github_webhook_secret:
           if not verify_github_signature(payload, x_hub_signature_256, settings.github_webhook_secret):
               raise HTTPException(status_code=401, detail="Invalid signature")

       # Only process push events
       if x_github_event != "push":
           return {"status": "ignored", "reason": f"Event type '{x_github_event}' not handled"}

       # Parse payload
       import json
       data = json.loads(payload)

       # Extract changed paths from commits
       changed_paths: set[str] = set()
       for commit in data.get("commits", []):
           changed_paths.update(commit.get("added", []))
           changed_paths.update(commit.get("modified", []))
           changed_paths.update(commit.get("removed", []))

       # Filter to only catalog paths (skills/, mcps/, tools/)
       catalog_paths = [
           p for p in changed_paths
           if p.startswith(("skills/", "mcps/", "tools/"))
       ]

       if not catalog_paths:
           return {"status": "ok", "synced": 0, "reason": "No catalog paths changed"}

       # Trigger partial sync
       result = await sync_service.sync_paths(list(catalog_paths))

       return {
           "status": "ok",
           "synced": result.created + result.updated + result.deleted,
           "created": result.created,
           "updated": result.updated,
           "deleted": result.deleted,
           "errors": result.errors,
       }
   ```

2. **Add sync service dependency** to `entrypoints/dependencies.py`:
   ```python
   from atlas.adapters.sync import GitCatalogSyncService
   from atlas.domain.interfaces import AbstractSyncService

   async def get_sync_service(
       content_repo: Annotated[AbstractContentRepository, Depends(get_content_repository)],
       catalog_repo: Annotated[AbstractCatalogRepository, Depends(get_catalog_repository)],
   ) -> AbstractSyncService:
       # Use a system user ID for webhook-created items
       # In production, this could be a dedicated system account
       from uuid import UUID
       system_author_id = UUID("00000000-0000-0000-0000-000000000000")
       return GitCatalogSyncService(content_repo, catalog_repo, system_author_id)

   # Add type alias
   SyncService = Annotated[AbstractSyncService, Depends(get_sync_service)]
   ```

3. **Add settings** for webhook secret (in `atlas/config.py` if not already):
   - `github_webhook_secret: Optional[str] = None` - For signature verification

4. **Register webhook router** in main API router or app setup (create note for integration).

5. Create or update `entrypoints/api/routes/__init__.py` to export webhook router.
  </action>
  <verify>
Run `cd backend && python -c "
from atlas.entrypoints.api.routes.webhooks import router, verify_github_signature

# Test signature verification
import hashlib
import hmac
secret = 'test-secret'
payload = b'{\"commits\": []}'
signature = 'sha256=' + hmac.new(secret.encode(), payload, hashlib.sha256).hexdigest()

assert verify_github_signature(payload, signature, secret) == True
assert verify_github_signature(payload, 'sha256=wrong', secret) == False
print('Webhook signature verification works')

# Check route exists
routes = [r.path for r in router.routes]
assert '/github' in routes or any('/github' in str(r.path) for r in router.routes)
print('Webhook endpoint registered at /webhooks/github')
"`.
  </verify>
  <done>
GitHub webhook endpoint exists at POST /webhooks/github, verifies signatures, extracts changed paths from push events, and triggers partial sync.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add manual sync endpoint and integration test</name>
  <files>
    backend/src/atlas/entrypoints/api/routes/sync.py
    backend/src/atlas/entrypoints/api/routes/__init__.py
  </files>
  <action>
Add manual sync endpoint for admin use and testing, plus verify full integration.

1. **Manual sync route** (`entrypoints/api/routes/sync.py`):
   ```python
   from typing import Annotated
   from fastapi import APIRouter, Depends

   from atlas.domain.interfaces import AbstractSyncService, SyncResult
   from atlas.entrypoints.dependencies import get_sync_service

   router = APIRouter(prefix="/sync", tags=["sync"])

   @router.post("/full")
   async def full_sync(
       sync_service: Annotated[AbstractSyncService, Depends(get_sync_service)],
   ) -> dict:
       """
       Trigger a full sync between git content and database catalog.

       This compares ALL files in git with ALL catalog items in database
       and reconciles differences. Useful for:
       - Initial population
       - Recovering from missed webhooks
       - Manual consistency checks

       Note: In production, this should be protected by admin authentication.
       """
       result = await sync_service.sync_all()

       return {
           "status": "ok",
           "created": result.created,
           "updated": result.updated,
           "deleted": result.deleted,
           "errors": result.errors,
       }
   ```

2. **Update routes __init__.py** to export both routers:
   ```python
   from atlas.entrypoints.api.routes.webhooks import router as webhooks_router
   from atlas.entrypoints.api.routes.sync import router as sync_router

   __all__ = ["webhooks_router", "sync_router"]
   ```

3. **Integration test** using in-memory implementations:
   Create a quick verification that the sync flow works end-to-end:
   - Create InMemoryContentRepository with some files
   - Create InMemoryCatalogRepository (empty)
   - Create GitCatalogSyncService with both
   - Call sync_all()
   - Verify catalog items were created

This should be runnable as a simple script for now (formal tests in later phase).
  </action>
  <verify>
Run `cd backend && python -c "
import asyncio
from uuid import uuid4
from atlas.adapters.in_memory.content_repository import InMemoryContentRepository
from atlas.adapters.in_memory.repositories import InMemoryCatalogRepository
from atlas.adapters.sync import GitCatalogSyncService

async def test_sync():
    # Setup
    content_repo = InMemoryContentRepository()
    catalog_repo = InMemoryCatalogRepository()
    system_author = uuid4()
    sync_service = GitCatalogSyncService(content_repo, catalog_repo, system_author)

    # Add some content files
    await content_repo.save_content('skills/code-review.md', '# Code Review Skill', 'init')
    await content_repo.save_content('tools/formatter.md', '# Formatter Tool', 'init')
    await content_repo.save_content('mcps/github.md', '# GitHub MCP', 'init')

    # Sync
    result = await sync_service.sync_all()

    # Verify
    assert result.created == 3, f'Expected 3 created, got {result.created}'
    assert result.errors == [], f'Unexpected errors: {result.errors}'

    # Verify items exist in catalog
    all_items = await catalog_repo.list_all()
    assert len(all_items) == 3, f'Expected 3 items, got {len(all_items)}'

    print(f'Full sync test passed: {result.created} items created')

    # Test deletion sync
    await content_repo.delete_content('skills/code-review.md', 'remove')
    result2 = await sync_service.sync_all()
    assert result2.deleted == 1, f'Expected 1 deleted, got {result2.deleted}'
    print(f'Delete sync test passed: {result2.deleted} items deleted')

asyncio.run(test_sync())
print('Sync integration test PASSED')
"`.
  </verify>
  <done>
Manual sync endpoint exists at POST /sync/full. Full integration verified: git files sync to database catalog items correctly (create, update, delete).
  </done>
</task>

</tasks>

<verification>
After all tasks complete:

1. **Import chain verification:**
   ```bash
   cd backend && python -c "
   # Domain interfaces
   from atlas.domain.interfaces import AbstractSyncService, SyncResult

   # Adapter implementation
   from atlas.adapters.sync import GitCatalogSyncService

   # Entrypoints
   from atlas.entrypoints.api.routes.webhooks import router as webhooks_router
   from atlas.entrypoints.api.routes.sync import router as sync_router
   from atlas.entrypoints.dependencies import get_sync_service

   print('All sync-related imports successful')
   "
   ```

2. **Interface implementation verification:**
   ```bash
   cd backend && python -c "
   from atlas.domain.interfaces import AbstractSyncService
   from atlas.adapters.sync import GitCatalogSyncService

   assert issubclass(GitCatalogSyncService, AbstractSyncService)
   print('GitCatalogSyncService correctly implements AbstractSyncService')
   "
   ```

3. **End-to-end sync verification:**
   ```bash
   cd backend && python -c "
   import asyncio
   from uuid import uuid4
   from atlas.adapters.in_memory.content_repository import InMemoryContentRepository
   from atlas.adapters.in_memory.repositories import InMemoryCatalogRepository
   from atlas.adapters.sync import GitCatalogSyncService
   from atlas.domain.entities import CatalogItemType

   async def e2e_test():
       # Setup repos
       content = InMemoryContentRepository()
       catalog = InMemoryCatalogRepository()
       sync = GitCatalogSyncService(content, catalog, uuid4())

       # Create file
       await content.save_content('skills/test.md', '# Test', 'add')

       # Sync specific path
       result = await sync.sync_paths(['skills/test.md'])
       assert result.created == 1

       # Verify item type
       items = await catalog.list_all()
       assert len(items) == 1
       assert items[0].type == CatalogItemType.SKILL
       assert items[0].git_path == 'skills/test.md'

       print('E2E sync verification passed')

   asyncio.run(e2e_test())
   "
   ```
</verification>

<success_criteria>
- AbstractSyncService interface defined in domain layer with sync_all() and sync_paths() methods
- GitCatalogSyncService implements full sync (compare all git vs all DB) and partial sync (specific paths)
- SyncResult dataclass captures created/updated/deleted counts and errors
- GitHub webhook endpoint at POST /webhooks/github verifies signatures and triggers partial sync
- Manual sync endpoint at POST /sync/full triggers full reconciliation
- Sync creates CatalogItem records for new git files
- Sync deletes CatalogItem records when git files are removed
- Sync updates CatalogItem.updated_at when files are modified
- Path prefix mapping works: skills/ -> SKILL, mcps/ -> MCP, tools/ -> TOOL
- Full integration test passes with in-memory implementations
- Phase 1 Success Criteria SC-03 from ROADMAP.md is now covered
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-data-architecture/01-05-SUMMARY.md`
</output>
